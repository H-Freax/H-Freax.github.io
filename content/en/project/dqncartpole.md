---
title: Equivariant DQN in CartPole
summary: A project that implements Deep Q-Networks (DQN) in OpenAI Gym's CartPole environment, employing equivariant model techniques to achieve faster training speeds.
tags:
- robotic
date: "2023-12-01"

# Optional external URL for project (replaces project detail page).
external_link: ""

image:
  caption: Photo by rawpixel on Unsplash
  focal_point: Smart

links:
url_code: ""
url_pdf: ""
url_slides: "https://medium.com/@limyoonaxi/mastering-cartpole-with-enhanced-deep-q-networks-an-in-depth-guide-to-equivariant-models-f7600d6118a4"
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

## Project Overview
This project focused on applying Deep Q-Networks (DQN) to solve the CartPole problem in the OpenAI Gym, a benchmark task in reinforcement learning. By leveraging equivariant model techniques, the project aimed to enhance the efficiency of training DQNs using both state and image inputs.
## Achievements
- **Equivariant Model Techniques**: Applied advanced equivariant model techniques to improve the generalization of the DQN, enabling it to learn more efficiently from the environment.
- **2x Training Speed**: Successfully achieved a twofold increase in training speed compared to conventional DQN approaches, significantly reducing the time required to reach optimal performance.
